{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "titlePath = '../dataset/Data_TitleInfo2.csv'\n",
    "studentPath = '../dataset/Data_StudentInfo.csv'\n",
    "submitPath = '../dataset/Data_SubmitRecord'\n",
    "\n",
    "\n",
    "# 获取题目数据\n",
    "def getTitle():\n",
    "    title = pd.read_csv(titlePath)\n",
    "    return title\n",
    "\n",
    "# 获取学生数据\n",
    "def getStudent():\n",
    "    student = pd.read_csv(studentPath)\n",
    "    return student.drop(columns=['index'])\n",
    "\n",
    "# 获取提交数据（班级号）\n",
    "def getSubmit(classId=1):\n",
    "    submit = pd.read_csv(os.path.join(submitPath, 'SubmitRecord-Class' + str(classId) + '.csv'))\n",
    "    return submit.drop(columns=['index'])\n",
    "\n",
    "# 所有提交数据\n",
    "def getAllSubmit():\n",
    "    submitRecords = []\n",
    "    for i in range(1, 16):\n",
    "        submitRecords.append(getSubmit(i))\n",
    "    return pd.concat(submitRecords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据清洗"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 简单清洗并合并数据\n",
    "def cleanMerge():\n",
    "    title = getTitle()\n",
    "    student = getStudent()\n",
    "    submit = getAllSubmit()\n",
    "\n",
    "    print(title.shape, student.shape, submit.shape)\n",
    "    submit = submit.drop_duplicates()\n",
    "    print(submit.shape)\n",
    "\n",
    "    # 去除提交记录中的错误student_id\n",
    "    # print(student['student_ID'].unique().shape)\n",
    "    # print(submit['student_ID'].unique().shape)\n",
    "    error_students = submit[~submit['student_ID'].isin(student['student_ID'])]\n",
    "    # print('errorid',error_students.shape,error_students['student_ID'].iloc[0])\n",
    "    submit = submit[submit['student_ID'] != error_students['student_ID'].iloc[0]]\n",
    "    print(submit.shape)\n",
    "\n",
    "\n",
    "    # 提交记录中，class错误的修正\n",
    "    print('-----')\n",
    "    print(submit['class'].unique())\n",
    "    error_rows = submit[submit['class'] == 'class']\n",
    "    for index,row in error_rows.iterrows():\n",
    "        id = row['student_ID']\n",
    "        # print(id)\n",
    "        # print(id, sbms.shape, sbms['class'].unique()[0])\n",
    "        submit.loc[index, 'class'] = submit[submit['student_ID'] == id]['class'].unique()[0]\n",
    "\n",
    "    print(submit['class'].unique())\n",
    "\n",
    "    # 检查题目id\n",
    "    print('-----')\n",
    "    print(title['title_ID'].unique().shape)\n",
    "    print(submit['title_ID'].unique().shape)\n",
    "\n",
    "    print('-----')\n",
    "    # merge的时候发现，提交数据和题目数据中的score冲突，更改了题目数据中score->fullscore\n",
    "    # 注意：题目数据使用的是TitleInfo2.csv\n",
    "    print(submit.shape, submit.columns)\n",
    "    merge1 = pd.merge(submit, student, on='student_ID')\n",
    "    print(merge1.shape, merge1.columns)\n",
    "    merge2 = pd.merge(merge1, title, on='title_ID')\n",
    "    print(merge2.shape, merge2.columns)\n",
    "\n",
    "    return merge2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38, 7) (1364, 4) (232818, 9)\n",
      "(231812, 9)\n",
      "(231811, 9)\n",
      "-----\n",
      "['Class1' 'class' 'Class2' 'Class3' 'Class4' 'Class5' 'Class6' 'Class7'\n",
      " 'Class8' 'Class9' 'Class10' 'Class11' 'Class12' 'Class13' 'Class14'\n",
      " 'Class15']\n",
      "['Class1' 'Class15' 'Class7' 'Class2' 'Class3' 'Class4' 'Class5' 'Class6'\n",
      " 'Class8' 'Class9' 'Class10' 'Class11' 'Class12' 'Class13' 'Class14']\n",
      "-----\n",
      "(38,)\n",
      "(38,)\n",
      "-----\n",
      "(231811, 9) Index(['class', 'time', 'state', 'score', 'title_ID', 'method', 'memory',\n",
      "       'timeconsume', 'student_ID'],\n",
      "      dtype='object')\n",
      "(231811, 12) Index(['class', 'time', 'state', 'score', 'title_ID', 'method', 'memory',\n",
      "       'timeconsume', 'student_ID', 'sex', 'age', 'major'],\n",
      "      dtype='object')\n",
      "(231811, 18) Index(['class', 'time', 'state', 'score', 'title_ID', 'method', 'memory',\n",
      "       'timeconsume', 'student_ID', 'sex', 'age', 'major', 'fullscore',\n",
      "       'knowledge_num', 'knowledge', 'sub_knowledge', 'knowledge2',\n",
      "       'sub_knowledge2'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/30 [00:00<?, ?it/s]/var/folders/_n/smz6g_y16tg_x85vpk78z5jh0000gp/T/ipykernel_3387/2168936426.py:29: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  newDf = pd.concat([newDf,pd.DataFrame([{\n",
      "100%|██████████| 30/30 [01:16<00:00,  2.55s/it]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "计算人-题数据特征\n",
    "'''\n",
    "df = cleanMerge()\n",
    "students = df['student_ID'].unique()\n",
    "titles = df['title_ID'].unique()\n",
    "#print(df[df.duplicated(subset=['student_ID', 'title_ID','time'],keep=False)].sort_values(by=['student_ID',\n",
    "\n",
    "newDf = pd.DataFrame(columns=['student_ID', 'title_ID', 'st_max_score', 'st_pfm_tc','st_pfm_mem','st_tt_subNum',\n",
    "                                'st_tt_period','st_fm_subNum','st_fm_period','st_errs','st_exploreNum'])\n",
    "for student in tqdm(students):\n",
    "    for title in titles:\n",
    "        studentTitle = df[(df['student_ID'] == student) & (df['title_ID'] == title)]\n",
    "        if studentTitle.empty: continue\n",
    "        max_score = studentTitle['score'].max()\n",
    "        tt_subNum = studentTitle.shape[0]\n",
    "        tt_period = studentTitle['time'].max() - studentTitle['time'].min()\n",
    "        fm_time= studentTitle[studentTitle['score'] == max_score]['time'].min()\n",
    "        pfm_tc= studentTitle[studentTitle['score'] == max_score]['timeconsume'].min()\n",
    "        pfm_mem= studentTitle[studentTitle['score'] == max_score]['memory'].min()\n",
    "        fm_subNum = studentTitle[studentTitle['time'] <= fm_time].shape[0]\n",
    "        fm_period = fm_time - studentTitle['time'].min()\n",
    "        st_errs = list(studentTitle[(studentTitle['state'] != 'Absolutely_Correct') & (studentTitle['state'] != 'Partially_Correct')]['state'].unique())\n",
    "        ac_flag = 1 if (studentTitle[studentTitle['state'] == 'Absolutely_Correct'].shape[0]) > 0 else 0\n",
    "        ac_time= studentTitle[studentTitle['state'] == 'Absolutely_Correct']['time'].min()\n",
    "        st_exploreNum = studentTitle[studentTitle['time'] < ac_time].shape[0]\n",
    "\n",
    "        newDf = pd.concat([newDf,pd.DataFrame([{\n",
    "            'student_ID':student,'title_ID':title,'st_max_score':max_score,\n",
    "            'st_pfm_tc':pfm_tc,'st_pfm_mem':pfm_mem,\n",
    "            'st_fm_time':fm_time,\n",
    "            'st_tt_subNum':tt_subNum,'st_tt_period':tt_period,\n",
    "            'st_fm_subNum':fm_subNum,'st_fm_period':fm_period,\n",
    "            'st_ac_flag':ac_flag,'st_ac_time':ac_time,\n",
    "            'st_errs':';'.join(st_errs),\n",
    "            'st_exploreNum':st_exploreNum\n",
    "            }])],ignore_index=False)\n",
    "newDf.to_csv('../dataset/Data_StudentTitleInfo.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
